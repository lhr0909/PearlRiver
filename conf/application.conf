akka {
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  loglevel = "DEBUG"
  actor {
    deployment {
      default {
        dispatcher = "xyz-dispatcher"
      }
    }
  }

  stream {
    materializer {
      dispatcher = "xyz-dispatcher"
    }
  }
//  log-config-on-start = on
}

xyz-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

future-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

# http服务器配置
http {
  # 绑定http服务的IP
  bind-address = "0.0.0.0"
  # 绑定http服务的端口号
  bind-port = 9090
}

# Kafka配置，里面key/value格式基本上和 [[ https://kafka.apache.org/documentation/#newconsumerconfigs ]] 一致
# 配置值最好用字符串包着
kafka {
  # Kafka服务器地址, 用逗号(,)分隔开<IP>:<port>配置
  bootstrap.servers = "0.0.0.0:9092"
  # Processor在Kafka里面注册的组名
  group.id = "xyz-processor"

  auto.offset.reset = "earliest"
}

# ES配置
elasticsearch {
  # ES Transport客户端地址
  transport-addresses = ["0.0.0.0:9300"]

  # ES Bulk配置
  bulk {
    # 每次Bulk的容量，单位可以用b, k/kb, m/mb, g/gb, t/tb, p/pb
    max-size-in-bytes = "5mb"
    # 每次Bulk的最大请求数
    max-actions = 15000
    # 如果Bulk超过这个秒数没有新事件进入，会自动触发bulk
    timeout = "20s"
  }

  # ES 创建index默认配置
  index {
    # 这里的配置和es的配置名字相同
    # 配置值最好用字符串包着

    # index刷新频率
    refresh_interval = "5s"
    # 每个index的分片(shard)数
    number_of_shards = "3"
    # 每个index的备份分片数
    number_of_replicas = "1"
    # 是否打开请求缓存
    requests.cache.enable = "true"
  }
}

# MySQL配置
dev {
  slick.driver=scala.slick.driver.MySQLDriver
  driver=com.mysql.jdbc.Driver
  url="jdbc:mysql://localhost:3306/xyz?characterEncoding=UTF-8"
  user="root"
  password="1qaz@3edc"
}

kamon {

  metric.filters {
    akka-actor {
      includes = [ "**" ]
    }

    akka-dispatcher {
      includes = [ "**" ]
    }

    akka-router {
      includes = [ "**" ]
    }
  }

  influxdb {
    application-name = "xyz-processor"

    subscriptions {
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
    }
  }

  internal-config {
    akka {
      loglevel = DEBUG

      actor.default-dispatcher {
        fork-join-executor.parallelism-factor = 1.0
      }
    }
  }

}