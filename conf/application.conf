akka {
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  loglevel = "DEBUG"
  actor {
    deployment {
      default {
        dispatcher = "xyz-dispatcher"
      }
    }
  }

  stream {
    materializer {
      dispatcher = "xyz-dispatcher"
    }
  }
//  log-config-on-start = on
}

xyz-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

future-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 64
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5
}

# http服务器配置
http {
  # 绑定http服务的IP
  bind-address = "0.0.0.0"
  # 绑定http服务的端口号
  bind-port = 9090
}

# Kafka配置
kafka {
  # Kafka服务器地址
  bootstrap-servers = ["0.0.0.0:9092"]
  # Processor在Kafka里面注册的组名
  consumer-group-id = "xyz-processor"

  # 其他Kafka属性配置
  properties {
    auto.offset.reset = "earliest"
  }
}

# ES配置
elasticsearch {
  # ES Transport客户端地址
  transport-addresses = ["0.0.0.0:9300"]

  # ES Bulk配置
  bulk {
    # 每次Bulk的容量，单位可以用b, k/kb, m/mb, g/gb, t/tb, p/pb
    max-size-in-bytes = "5mb"
    # 每次Bulk的最大请求数
    max-actions = 15000
    # 如果Bulk超过这个秒数没有新事件进入，会自动触发bulk
    timeout = "20s"
  }

  # ES 创建index默认配置
  index {
    # 这里的配置和es的配置名字相同，不过配置值最好用字符串包着

    # index刷新频率
    refresh_interval = "5s"
    # 每个index的分片(shard)数
    number_of_shards = "3"
    # 每个index的备份分片数
    number_of_replicas = "1"
    # 是否打开请求缓存
    requests.cache.enable = "true"
  }
}

# MySQL配置
dev {
  slick.driver=scala.slick.driver.MySQLDriver
  driver=com.mysql.jdbc.Driver
  url="jdbc:mysql://localhost:3306/xyz?characterEncoding=UTF-8"
  user="root"
  password="1qaz@3edc"
}

# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that blocking of the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms

  # The stage will be await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `TimeoutException`.
  commit-timeout = 15s

  # If the KafkaConsumer can't connect to the broker the poll will be
  # aborted after this timeout. The KafkaConsumerActor will throw
  # org.apache.kafka.common.errors.WakeupException which will be ignored
  # until max-wakeups limit gets exceeded.
  wakeup-timeout = 3s

  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
  max-wakeups = 10

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "xyz-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    # Disable auto-commit by default
    enable.auto.commit = false
  }
}

kamon {

  metric.filters {
    akka-actor {
      includes = [ "**" ]
    }

    akka-dispatcher {
      includes = [ "**" ]
    }

    akka-router {
      includes = [ "**" ]
    }
  }

  influxdb {
    application-name = "xyz-processor"

    subscriptions {
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
    }
  }

  internal-config {
    akka {
      loglevel = DEBUG

      actor.default-dispatcher {
        fork-join-executor.parallelism-factor = 1.0
      }
    }
  }

}